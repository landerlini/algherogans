{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7bb813-6606-4bc2-a1ac-55b1b810d31e",
   "metadata": {},
   "source": [
    "# Autoencoders and Generative Adversarial Networks - Part 3/3\n",
    "### XX Seminar on Software for Nuclear, Subnuclear and Applied Physics, 4-9 June 2023, Hotel Porto Conte, Maristella SS, IT\n",
    "\n",
    "Contacts: \n",
    " * email: Lucio.Anderlini [at] fi.infn.it\n",
    " * GitHub: [github.com/landerlini](https://github.com/landerlini)\n",
    "\n",
    "## Generative Adversarial Networks and conditioning\n",
    "\n",
    "In this notebook we will focus on using autoencoders as generative models. We will define the concept of conditioning and we will introduce an alternative System of Neural Networks, Generative Adversarial Networks.\n",
    "\n",
    "## Setting the scene\n",
    "\n",
    "Let's copy-paste from the previous lecture the steps of data pre-processing and the `rough_inspection` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3bd7eb-4b49-4b02-8eaa-e85310114819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def rough_inspection(dataset, n_fig=4):\n",
    "    figure = np.concatenate([np.reshape(dataset[n_fig*i:n_fig*(i+1)], (n_fig*28, 28)) for i in range(n_fig)], axis=1)\n",
    "\n",
    "    plt.figure(figsize=(7,2))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(figure, cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(dataset.flatten(), bins=50)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Pixel value\")\n",
    "    plt.show()\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "train_idx = sum([np.arange(len(y_train))[y_train == i].tolist()[:4] for i in range(10)], [])\n",
    "test_idx = sum([np.arange(len(y_test))[y_test == i].tolist()[:4] for i in range(10)], [])\n",
    "\n",
    "Lx_train = x_train[train_idx]\n",
    "Lx_test = x_test[test_idx]\n",
    "Ly_train = y_train[train_idx]\n",
    "Ly_test = y_test[test_idx]\n",
    "\n",
    "px_train = (x_train / x_train.max())\n",
    "px_test = (x_test / x_train.max()) \n",
    "pLx_train = (Lx_train / x_train.max())\n",
    "pLx_test = (Lx_test / x_train.max()) \n",
    "\n",
    "py_train = np.stack([y_train == i for i in range(10)], axis=1)\n",
    "py_test = np.stack([y_test == i for i in range(10)], axis=1)\n",
    "\n",
    "rough_inspection(px_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568f2fcf-d6d9-472e-ad9e-67593eb516de",
   "metadata": {},
   "source": [
    "## Autoencoders as Generators\n",
    "\n",
    "Let's restart from our example of autoencoder with pinned labels in the latent space.\n",
    "Let's define a slightly deeper network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef4c914-db87-41a4-948f-ebd1c2bd8de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 09:33:29.127771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-04 09:33:29.155753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-04 09:33:29.156943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-04 09:33:29.159272: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-04 09:33:29.161076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-04 09:33:29.162128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-04 09:33:29.163164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so retur"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 8)         80        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 32)          4640      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,410\n",
      "Trainable params: 28,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ning NUMA node zero\n",
      "2023-06-04 09:33:29.628867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-04 09:33:29.630053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-04 09:33:29.631081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-04 09:33:29.632073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 376 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 1g.10gb, pci bus id: 0000:00:05.0, compute capability: 8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 32)                96        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 49)                1617      \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 1)           0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 7, 7, 32)         160       \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 7, 7, 32)         4128      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 14, 14, 16)       2064      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 14, 14, 16)       1040      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 28, 28, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 28, 28, 8)        520       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 1)        33        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 28, 28)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,658\n",
      "Trainable params: 9,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose, Reshape, MaxPooling2D, UpSampling2D, Flatten\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "encoder = Sequential([\n",
    "    Reshape((28, 28, 1)),\n",
    "    Conv2D(8, kernel_size=3, padding='same', activation='relu'),\n",
    "    Conv2D(8, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(16, kernel_size=3, padding='same', activation='relu'),\n",
    "    Conv2D(16, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(32, kernel_size=3, padding='same', activation='relu'),\n",
    "    Conv2D(32, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='tanh'),\n",
    "    Dense(32, activation='tanh'),\n",
    "    Dense(2, activation='linear')\n",
    "])\n",
    "\n",
    "encoder.build(input_shape=(None, 28, 28))\n",
    "display(encoder.summary())\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(32, activation='tanh'),\n",
    "    Dense(28//4*28//4, activation='tanh'),\n",
    "    Reshape((28//4, 28//4, 1)),\n",
    "    Conv2DTranspose(32, kernel_size=(2, 2), padding='same', activation='relu'),\n",
    "    Conv2DTranspose(32, kernel_size=(2, 2), padding='same', activation='relu'),\n",
    "    UpSampling2D(size=(2 ,2)),\n",
    "    Conv2DTranspose(16, kernel_size=(2, 2), padding='same', activation='relu'),\n",
    "    Conv2DTranspose(16, kernel_size=(2, 2), padding='same', activation='relu'),\n",
    "    UpSampling2D(size=(2 ,2)),\n",
    "    Conv2DTranspose(8, kernel_size=(2, 2), padding='same', activation='relu'),\n",
    "    Conv2DTranspose(1, kernel_size=(2, 2), padding='same', activation='sigmoid'),\n",
    "    Reshape((28,28)),\n",
    "])\n",
    "decoder.build(input_shape=encoder.output_shape)\n",
    "\n",
    "display(decoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedd1cf2-48b3-43f4-a7d9-758682494ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]2023-06-04 09:33:40.124469: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 71.78MiB (rounded to 75264000)requested by op Conv2D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-06-04 09:33:40.124572: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] BFCAllocator dump for GPU_0_bfc\n",
      "2023-06-04 09:33:40.124586: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (256): \tTotal Chunks: 72, Chunks in use: 72. 18.0KiB allocated for chunks. 18.0KiB in use in bin. 4.2KiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124594: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (512): \tTotal Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 1.6KiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124599: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1024): \tTotal Chunks: 2, Chunks in use: 1. 2.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124605: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2048): \tTotal Chunks: 4, Chunks in use: 4. 8.5KiB allocated for chunks. 8.5KiB in use in bin. 8.5KiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124610: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4096): \tTotal Chunks: 12, Chunks in use: 9. 59.2KiB allocated for chunks. 43.5KiB in use in bin. 41.2KiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124617: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8192): \tTotal Chunks: 23, Chunks in use: 23. 257.2KiB allocated for chunks. 257.2KiB in use in bin. 256.7KiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124622: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16384): \tTotal Chunks: 6, Chunks in use: 4. 108.0KiB allocated for chunks. 72.0KiB in use in bin. 68.0KiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124628: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (32768): \tTotal Chunks: 4, Chunks in use: 4. 144.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124635: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0. 72.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124642: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124647: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124652: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124657: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124661: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124667: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 5.98MiB allocated for chunks. 5.98MiB in use in bin. 5.98MiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124672: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 1. 8.97MiB allocated for chunks. 8.97MiB in use in bin. 8.97MiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124679: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (16777216): \tTotal Chunks: 20, Chunks in use: 19. 360.39MiB allocated for chunks. 340.94MiB in use in bin. 340.94MiB client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124684: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124717: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124722: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124727: I tensorflow/core/common_runtime/bfc_allocator.cc:1034] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-04 09:33:40.124733: I tensorflow/core/common_runtime/bfc_allocator.cc:1050] Bin for 71.78MiB was 64.00MiB, Chunk State: \n",
      "2023-06-04 09:33:40.124738: I tensorflow/core/common_runtime/bfc_allocator.cc:1063] Next region of size 394264576\n",
      "  0%|          | 0/30 [00:10<?, ?it/s] 09:33:40.124756: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000000 of size 256 next 1\n",
      "2023-06-04 09:33:40.124761: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000100 of size 1280 next 2\n",
      "2023-06-04 09:33:40.124765: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000600 of size 256 next 3\n",
      "2023-06-04 09:33:40.124813: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000700 of size 256 next 4\n",
      "2023-06-04 09:33:40.124819: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000800 of size 256 next 5\n",
      "2023-06-04 09:33:40.124823: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000900 of size 256 next 6\n",
      "2023-06-04 09:33:40.124827: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000a00 of size 256 next 9\n",
      "2023-06-04 09:33:40.124831: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000b00 of size 256 next 10\n",
      "2023-06-04 09:33:40.124836: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000c00 of size 256 next 7\n",
      "2023-06-04 09:33:40.124840: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000d00 of size 512 next 8\n",
      "2023-06-04 09:33:40.124845: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8000f00 of size 256 next 11\n",
      "2023-06-04 09:33:40.124849: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001000 of size 256 next 14\n",
      "2023-06-04 09:33:40.124853: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001100 of size 256 next 15\n",
      "2023-06-04 09:33:40.124857: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001200 of size 256 next 18\n",
      "2023-06-04 09:33:40.124862: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001300 of size 256 next 19\n",
      "2023-06-04 09:33:40.124866: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001400 of size 256 next 22\n",
      "2023-06-04 09:33:40.124870: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001500 of size 256 next 23\n",
      "2023-06-04 09:33:40.124874: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001600 of size 256 next 24\n",
      "2023-06-04 09:33:40.124878: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001700 of size 256 next 25\n",
      "2023-06-04 09:33:40.124883: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001800 of size 256 next 28\n",
      "2023-06-04 09:33:40.124887: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001900 of size 256 next 29\n",
      "2023-06-04 09:33:40.124891: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001a00 of size 256 next 32\n",
      "2023-06-04 09:33:40.124895: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001b00 of size 256 next 33\n",
      "2023-06-04 09:33:40.124899: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001c00 of size 256 next 34\n",
      "2023-06-04 09:33:40.124905: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001d00 of size 256 next 36\n",
      "2023-06-04 09:33:40.124910: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001e00 of size 256 next 37\n",
      "2023-06-04 09:33:40.124914: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8001f00 of size 256 next 38\n",
      "2023-06-04 09:33:40.124918: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8002000 of size 256 next 12\n",
      "2023-06-04 09:33:40.124922: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8002100 of size 2304 next 13\n",
      "2023-06-04 09:33:40.124927: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8002a00 of size 4096 next 63\n",
      "2023-06-04 09:33:40.124931: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8003a00 of size 256 next 62\n",
      "2023-06-04 09:33:40.124935: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8003b00 of s\n",
      "ize 256 next 64\n",
      "2023-06-04 09:33:40.124939: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8003c00 of size 256 next 65\n",
      "2023-06-04 09:33:40.124943: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8003d00 of size 256 next 66\n",
      "2023-06-04 09:33:40.124948: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8003e00 of size 256 next 67\n",
      "2023-06-04 09:33:40.124952: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8003f00 of size 256 next 69\n",
      "2023-06-04 09:33:40.124956: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004000 of size 256 next 70\n",
      "2023-06-04 09:33:40.124960: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004100 of size 256 next 71\n",
      "2023-06-04 09:33:40.124964: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004200 of size 256 next 110\n",
      "2023-06-04 09:33:40.124969: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004300 of size 256 next 111\n",
      "2023-06-04 09:33:40.124973: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004400 of size 256 next 114\n",
      "2023-06-04 09:33:40.124977: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004500 of size 256 next 122\n",
      "2023-06-04 09:33:40.124981: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004600 of size 256 next 123\n",
      "2023-06-04 09:33:40.124986: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004700 of size 256 next 125\n",
      "2023-06-04 09:33:40.124990: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004800 of size 256 next 127\n",
      "2023-06-04 09:33:40.124994: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004900 of size 256 next 117\n",
      "2023-06-04 09:33:40.124998: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004a00 of size 512 next 118\n",
      "2023-06-04 09:33:40.125002: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004c00 of size 256 next 115\n",
      "2023-06-04 09:33:40.125006: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004d00 of size 256 next 17\n",
      "2023-06-04 09:33:40.125011: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8004e00 of size 4608 next 16\n",
      "2023-06-04 09:33:40.125015: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8006000 of size 4096 next 40\n",
      "2023-06-04 09:33:40.125019: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007000 of size 256 next 39\n",
      "2023-06-04 09:33:40.125023: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007100 of size 256 next 41\n",
      "2023-06-04 09:33:40.125028: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007200 of size 256 next 42\n",
      "2023-06-04 09:33:40.125032: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007300 of size 256 next 43\n",
      "2023-06-04 09:33:40.125036: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007400 of size 256 next 44\n",
      "2023-06-04 09:33:40.125040: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007500 of size 256 next 45\n",
      "2023-06-04 09:33:40.125044: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007600 of size 256 next 48\n",
      "2023-06-04 09:33:40.125048: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007700 of size 256 next 49\n",
      "2023-06-04 09:33:40.125053: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007800 of size 256 next 50\n",
      "2023-06-04 09:33:40.125057: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007900 of size 256 next 57\n",
      "2023-06-04 09:33:40.125061: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007a00 of size 256 next 58\n",
      "2023-06-04 09:33:40.125065: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007b00 of size 256 next 59\n",
      "2023-06-04 09:33:40.125069: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007c00 of size 256 next 61\n",
      "2023-06-04 09:33:40.125073: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007d00 of size 256 next 53\n",
      "2023-06-04 09:33:40.125077: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8007e00 of size 512 next 54\n",
      "2023-06-04 09:33:40.125081: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8008000 of size 256 next 51\n",
      "2023-06-04 09:33:40.125086: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8008100 of size 256 next 52\n",
      "2023-06-04 09:33:40.125090: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8008200 of size 256 next 55\n",
      "2023-06-04 09:33:40.125094: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8008300 of size 256 next 21\n",
      "2023-06-04 09:33:40.125098: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8008400 of size 9216 next 20\n",
      "2023-06-04 09:33:40.125103: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a800a800 of size 2048 next 68\n",
      "2023-06-04 09:33:40.125108: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a800b000 of size 4352 next 47\n",
      "2023-06-04 09:33:40.125113: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a800c100 of size 6400 next 46\n",
      "2023-06-04 09:33:40.125117: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a800da00 of size 12032 next 91\n",
      "2023-06-04 09:33:40.125121: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8010900 of size 12032 next 27\n",
      "2023-06-04 09:33:40.125126: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8013800 of size 18432 next 26\n",
      "2023-06-04 09:33:40.125130: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018000 of size 256 next 128\n",
      "2023-06-04 09:33:40.125135: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018100 of size 256 next 132\n",
      "2023-06-04 09:33:40.125139: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018200 of size 256 next 135\n",
      "2023-06-04 09:33:40.125143: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018300 of size 256 next 136\n",
      "2023-06-04 09:33:40.125147: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018400 of size 256 next 130\n",
      "2023-06-04 09:33:40.125151: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018500 of size 512 next 131\n",
      "2023-06-04 09:33:40.125155: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018700 of size 256 next 141\n",
      "2023-06-04 09:33:40.125160: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018800 of size 256 next 144\n",
      "2023-06-04 09:33:40.125164: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018900 of size 256 next 146\n",
      "2023-06-04 09:33:40.125168: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018a00 of size 256 next 147\n",
      "2023-06-04 09:33:40.125172: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8018b00 of size 256 next 148\n",
      "2023-06-04 09:33:40.125177: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f67a8018c00 of size 1024 next 124\n",
      "2023-06-04 09:33:40.125182: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8019000 of size 4096 next 60\n",
      "2023-06-04 09:33:40.125186: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a801a000 of size 8192 next 56\n",
      "2023-06-04 09:33:40.125191: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a801c000 of size 20480 next 31\n",
      "2023-06-04 09:33:40.125195: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8021000 of size 36864 next 30\n",
      "2023-06-04 09:33:40.125200: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a802a000 of size 36864 next 35\n",
      "2023-06-04 09:33:40.125204: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a8033000 of size 18816000 next 72\n",
      "2023-06-04 09:33:40.125209: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67a9224c00 of size 18816000 next 73\n",
      "2023-06-04 09:33:40.125213: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67aa416800 of size 18816000 next 74\n",
      "2023-06-04 09:33:40.125217: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67ab608400 of size 18816000 next 75\n",
      "2023-06-04 09:33:40.125222: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67ac7fa000 of size 18816000 next 76\n",
      "2023-06-04 09:33:40.125226: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67ad9ebc00 of size 18816000 next 77\n",
      "2023-06-04 09:33:40.125230: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67aebdd800 of size 18816000 next 78\n",
      "2023-06-04 09:33:40.125234: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67afdcf400 of size 18816000 next 79\n",
      "2023-06-04 09:33:40.125238: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67b0fc1000 of size 18816000 next 80\n",
      "2023-06-04 09:33:40.125242: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67b21b2c00 of size 18816000 next 81\n",
      "2023-06-04 09:33:40.125247: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67b33a4800 of size 18816000 next 82\n",
      "2023-06-04 09:33:40.125251: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67b4596400 of size 18816000 next 83\n",
      "2023-06-04 09:33:40.125255: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67b5788000 of size 18816000 next 84\n",
      "2023-06-04 09:33:40.125259: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67b6979c00 of size 18816000 next 85\n",
      "2023-06-04 09:33:40.125263: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67b7b6b800 of size 18816000 next 86\n",
      "2023-06-04 09:33:40.125267: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67b8d5d400 of size 18816000 next 87\n",
      "2023-06-04 09:33:40.125271: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67b9f4f000 of size 18816000 next 88\n",
      "2023-06-04 09:33:40.125283: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bb140c00 of size 18816000 next 89\n",
      "2023-06-04 09:33:40.125287: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bc332800 of size 18816000 next 90\n",
      "2023-06-04 09:33:40.125292: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd524400 of size 12032 next 92\n",
      "2023-06-04 09:33:40.125296: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd527300 of size 12032 next 93\n",
      "2023-06-04 09:33:40.125300: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd52a200 of size 12032 next 94\n",
      "2023-06-04 09:33:40.125304: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd52d100 of size 12032 next 95\n",
      "2023-06-04 09:33:40.125308: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd530000 of size 12032 next 96\n",
      "2023-06-04 09:33:40.125313: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd532f00 of size 12032 next 97\n",
      "2023-06-04 09:33:40.125318: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd535e00 of size 12032 next 98\n",
      "2023-06-04 09:33:40.125323: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd538d00 of size 12032 next 99\n",
      "2023-06-04 09:33:40.125327: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd53bc00 of size 12032 next 100\n",
      "2023-06-04 09:33:40.125331: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd53eb00 of size 12032 next 101\n",
      "2023-06-04 09:33:40.125335: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd541a00 of size 12032 next 102\n",
      "2023-06-04 09:33:40.125339: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd544900 of size 12032 next 103\n",
      "2023-06-04 09:33:40.125344: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd547800 of size 12032 next 104\n",
      "2023-06-04 09:33:40.125348: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd54a700 of size 12032 next 105\n",
      "2023-06-04 09:33:40.125352: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd54d600 of size 12032 next 106\n",
      "2023-06-04 09:33:40.125356: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd550500 of size 12032 next 107\n",
      "2023-06-04 09:33:40.125360: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd553400 of size 12032 next 108\n",
      "2023-06-04 09:33:40.125365: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bd556300 of size 6272000 next 109\n",
      "2023-06-04 09:33:40.125369: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb51700 of size 2048 next 126\n",
      "2023-06-04 09:33:40.125373: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f67bdb51f00 of size 4352 next 113\n",
      "2023-06-04 09:33:40.125377: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb53000 of size 6400 next 112\n",
      "2023-06-04 09:33:40.125382: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb54900 of size 2304 next 129\n",
      "2023-06-04 09:33:40.125386: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb55200 of size 5888 next 121\n",
      "2023-06-04 09:33:40.125390: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb56900 of size 8192 next 116\n",
      "2023-06-04 09:33:40.125394: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f67bdb58900 of size 4608 next 134\n",
      "2023-06-04 09:33:40.125398: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb59b00 of size 4608 next 133\n",
      "2023-06-04 09:33:40.125403: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f67bdb5ad00 of size 7168 next 119\n",
      "2023-06-04 09:33:40.125407: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb5c900 of size 16384 next 120\n",
      "2023-06-04 09:33:40.125411: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f67bdb60900 of size 18432 next 138\n",
      "2023-06-04 09:33:40.125415: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb65100 of size 9216 next 137\n",
      "2023-06-04 09:33:40.125420: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f67bdb67500 of size 18432 next 139\n",
      "2023-06-04 09:33:40.125424: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb6bd00 of size 18432 next 140\n",
      "2023-06-04 09:33:40.125428: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f67bdb70500 of size 73728 next 143\n",
      "2023-06-04 09:33:40.125432: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb82500 of size 36864 next 142\n",
      "2023-06-04 09:33:40.125436: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb8b500 of size 36864 next 145\n",
      "2023-06-04 09:33:40.125441: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] InUse at 7f67bdb94500 of size 9408000 next 149\n",
      "2023-06-04 09:33:40.125445: I tensorflow/core/common_runtime/bfc_allocator.cc:1083] Free  at 7f67be48d300 of size 20393216 next 18446744073709551615\n",
      "2023-06-04 09:33:40.125451: I tensorflow/core/common_runtime/bfc_allocator.cc:1088]      Summary of in-use Chunks by size: \n",
      "2023-06-04 09:33:40.125459: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 72 Chunks of size 256 totalling 18.0KiB\n",
      "2023-06-04 09:33:40.125465: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 512 totalling 2.0KiB\n",
      "2023-06-04 09:33:40.125470: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-06-04 09:33:40.125474: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 2048 totalling 4.0KiB\n",
      "2023-06-04 09:33:40.125479: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 2304 totalling 4.5KiB\n",
      "2023-06-04 09:33:40.125484: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 3 Chunks of size 4096 totalling 12.0KiB\n",
      "2023-06-04 09:33:40.125489: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 4352 totalling 4.2KiB\n",
      "2023-06-04 09:33:40.125494: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 4608 totalling 9.0KiB\n",
      "2023-06-04 09:33:40.125498: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 5888 totalling 5.8KiB\n",
      "2023-06-04 09:33:40.125503: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 6400 totalling 12.5KiB\n",
      "2023-06-04 09:33:40.125508: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 8192 totalling 16.0KiB\n",
      "2023-06-04 09:33:40.125513: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 9216 totalling 18.0KiB\n",
      "2023-06-04 09:33:40.125517: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 19 Chunks of size 12032 totalling 223.2KiB\n",
      "2023-06-04 09:33:40.125522: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 16384 totalling 16.0KiB\n",
      "2023-06-04 09:33:40.125527: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 2 Chunks of size 18432 totalling 36.0KiB\n",
      "2023-06-04 09:33:40.125532: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 20480 totalling 20.0KiB\n",
      "2023-06-04 09:33:40.125536: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 4 Chunks of size 36864 totalling 144.0KiB\n",
      "2023-06-04 09:33:40.125541: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 6272000 totalling 5.98MiB\n",
      "2023-06-04 09:33:40.125546: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 1 Chunks of size 9408000 totalling 8.97MiB\n",
      "2023-06-04 09:33:40.125551: I tensorflow/core/common_runtime/bfc_allocator.cc:1091] 19 Chunks of size 18816000 totalling 340.94MiB\n",
      "2023-06-04 09:33:40.125555: I tensorflow/core/common_runtime/bfc_allocator.cc:1095] Sum Total of in-use chunks: 356.43MiB\n",
      "2023-06-04 09:33:40.125560: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] total_region_allocated_bytes_: 394264576 memory_limit_: 394264576 available bytes: 0 curr_region_allocation_bytes_: 788529152\n",
      "2023-06-04 09:33:40.125571: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] Stats: \n",
      "Limit:                       394264576\n",
      "InUse:                       373743616\n",
      "MaxInUse:                    373743616\n",
      "NumAllocs:                         244\n",
      "MaxAllocSize:                 18816000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-06-04 09:33:40.125581: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ***********************************************************************************************_____\n",
      "2023-06-04 09:33:40.125662: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:684 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[3000,28,28,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"conv2d\" (type Conv2D).\n\nOOM when allocating tensor with shape[3000,28,28,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]\n\nCall arguments received by layer \"conv2d\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(3000, 28, 28, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk, label_chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(chunks, label_chunks):\n\u001b[0;32m---> 56\u001b[0m         losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mae_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_chunk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     57\u001b[0m         val_losses\u001b[38;5;241m.\u001b[39mappend(ae_test_step(val_chunk, val_label))\n\u001b[1;32m     59\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mae_train_step\u001b[0;34m(train_data, labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m ae_vars \u001b[38;5;241m=\u001b[39m enc_vars \u001b[38;5;241m+\u001b[39m dec_vars\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tp:\n\u001b[0;32m---> 10\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m decoder(encoded)\n\u001b[1;32m     13\u001b[0m     pins \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack([tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mcos(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m*\u001b[39mlabels\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m), tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39msin(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m*\u001b[39mlabels\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/envs/root/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/envs/root/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n\nOOM when allocating tensor with shape[3000,28,28,8] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]\n\nCall arguments received by layer \"conv2d\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(3000, 28, 28, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "ae_optimizer = Adam(1e-3)\n",
    "\n",
    "def ae_train_step(train_data, labels):\n",
    "    enc_vars = encoder.trainable_weights\n",
    "    dec_vars = decoder.trainable_weights\n",
    "\n",
    "    ae_vars = enc_vars + dec_vars\n",
    "\n",
    "    with tf.GradientTape() as tp:\n",
    "        encoded = encoder(train_data)\n",
    "        decoded = decoder(encoded)\n",
    "\n",
    "        pins = tf.stack([tf.math.cos(2*np.pi*labels/10), tf.math.sin(2*np.pi*labels/10)], axis=1)\n",
    "        labeled_loss = tf.reduce_mean(\n",
    "            tf.where(tf.math.is_finite(labels), tf.linalg.norm(encoded - pins, axis=1), 0.)\n",
    "        )\n",
    "        \n",
    "        loss = BinaryCrossentropy()(train_data, decoded) + 0.1*labeled_loss\n",
    "\n",
    "    ae_grads = tp.gradient(loss, ae_vars)\n",
    "    ae_optimizer.apply_gradients(zip(ae_grads, ae_vars))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def ae_test_step(test_data, labels):\n",
    "    encoded = encoder(test_data)\n",
    "    decoded = decoder(encoded)\n",
    "\n",
    "    pins = tf.stack([tf.math.cos(2*np.pi*labels/10), tf.math.sin(2*np.pi*labels/10)], axis=1)\n",
    "    labeled_loss = tf.reduce_mean(\n",
    "        tf.where(tf.math.is_finite(labels), tf.linalg.norm(encoded - pins, axis=1), 0.)\n",
    "    )\n",
    "        \n",
    "    loss = BinaryCrossentropy()(test_data, decoded) + 0.1*labeled_loss\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "chunks = [tf.constant(c) for c in np.split(px_train, 20)[:-1]]\n",
    "label_chunks = [tf.constant(c, dtype=tf.float32) for c in np.split(y_train, 20)[:-1]]\n",
    "\n",
    "val_chunk = tf.constant(px_test[:1000])\n",
    "val_label = tf.constant(y_test[:1000], dtype=tf.float32)\n",
    "\n",
    "\n",
    "## Reset the weights\n",
    "from tensorflow.keras.models import clone_model\n",
    "decoder = clone_model(decoder)\n",
    "encoder = clone_model(encoder)\n",
    "\n",
    "from tqdm import trange\n",
    "for epoch in trange(30):\n",
    "    for chunk, label_chunk in zip(chunks, label_chunks):\n",
    "        losses.append(ae_train_step(chunk, label_chunk))\n",
    "        val_losses.append(ae_test_step(val_chunk, val_label))\n",
    "\n",
    "plt.plot(losses, label=\"Training\")\n",
    "plt.plot(val_losses, label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb9d2c-d839-48ff-a853-6c08d3424672",
   "metadata": {},
   "source": [
    "Now we can sample the latent space with random points selected around the pin for a specific point and use the decoder to \"generate\" a new image from that point.\n",
    "\n",
    "In this way we can generate new digits, never actually \"seen\" by the autoencoder but ***conditioned*** in the sense we introduce a condition on the generation (in this case the label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a297d-c393-4393-b297-f0b6e2352009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_digit(digit, decoder_net, n_fig=8):\n",
    "    label = np.c_[np.cos(2*np.pi*digit/10), np.sin(2*np.pi*digit/10)]\n",
    "    encoded = np.random.normal(label, 0.1, (n_fig*n_fig, 2))\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(encoded[:,0], encoded[:, 1], s=1)\n",
    "    plt.ylim(-1.4, 1.4)\n",
    "    plt.xlim(-1.4, 1.4)\n",
    "    \n",
    "    decoded = decoder_net.predict(encoded)\n",
    "    figure = np.concatenate([np.reshape(decoded[n_fig*i:n_fig*(i+1)], (n_fig*28, 28)) for i in range(n_fig)], axis=1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(figure, cmap='gray')\n",
    "\n",
    "test_digit(1, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3579768e-5b37-4ef3-934e-86c1b935420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_digit(2, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058a638-8309-47ad-ac3a-df6c03606c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_digit(2.5, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd29cd3-732f-445b-a791-67514c0f229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_digit(3, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aecbcd-04d2-41be-9bf3-6987ba6033d9",
   "metadata": {},
   "source": [
    "Observing the generated digits we notice they are all very similar to each other. The decoder is not really representing the variability of possible digits we have in the training sample. This happens, again, because there is not a notion of probability on the generated sample, so even one single image capable of minimizing the loss function for all digit would be (possibly local) minimum of the loss function.\n",
    "\n",
    "We learned that we can use an adversial approach to introduce the notion of distribution in the training loop. Let's try to do the same thing (though in a much more abstract way) imposing a distribution to the space of the generated images instead of setting the distribution in the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360eb4b-7a17-4267-b66e-c9cecc711599",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "Actually, we can completely drop the encoder part and keep only the *decoder*, now named **generator** taking as an input randomly generated entries in the latent space.\n",
    "Then, we will redefine the adversarial classifier which was trying to classify encoded features vs. randomly generated entries in the encoded space with a new classifier, named **discriminator** trying to classify images in the training sample vs. generated images.\n",
    "\n",
    "As done for the adversarial autoencoder, we will try to maximize the loss of the discriminator tuning the weights of the **generator**, forcing it to generate images with a **probability distribution** indistinguishable from that of the input images.\n",
    "\n",
    "Generative adversarial networks (GANs) are a powerful framework for learning generative models from data. A GAN consists of two neural networks: a generator that produces synthetic data from a random input, and a discriminator that tries to distinguish between real and fake data. The generator and the discriminator are trained in an adversarial manner, where the generator tries to fool the discriminator and the discriminator tries to correctly classify the data. The goal of the GAN is to find a Nash equilibrium where the generator produces realistic data and the discriminator cannot tell them apart from the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5495ab-fdcc-45c2-9d34-08ef003dc866",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The generator is a simplified version of the DECODER defined in the previous notebooks\n",
    "generator = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(7*7*8, activation='tanh'),\n",
    "    Reshape((7, 7, 8)),\n",
    "    Conv2DTranspose(8, kernel_size=(3,3), activation='tanh', padding='same'),\n",
    "    UpSampling2D(size=(2,2)),\n",
    "    Conv2DTranspose(16, kernel_size=(3,3), activation='tanh', padding='same'),\n",
    "    UpSampling2D(size=(2,2)),\n",
    "    Conv2DTranspose(1, kernel_size=(3,3), activation='sigmoid', padding='same'),\n",
    "    Reshape((28, 28))\n",
    "])\n",
    "generator.build(input_shape=(None, 28, 28, 1))\n",
    "\n",
    "display(generator.summary())\n",
    "\n",
    "\n",
    "## The discriminator is a classifier taking images as input (and then we can use effectively convolutional layers)\n",
    "## and generating a boolean output: 1 if the image is generated or 0 if it is sampled from the training dataset\n",
    "discriminator = Sequential([\n",
    "    Reshape((28, 28, 1)),\n",
    "    Conv2D(16, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=L2(1e-3)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(8, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=L2(1e-3)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(4, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=L2(1e-3)),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='tanh'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "discriminator.build(input_shape=(None, 28, 28))\n",
    "display(discriminator.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88390fb-f75a-4cf7-bdfd-96799c435659",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "The training loop is very similar to what we discussed for the adversarial autoencoders.\n",
    "Here we are adopting some trick to stabilize the adversarial training.\n",
    "\n",
    "Making adversarial training stable and successful is an entier field of research. \n",
    "At the time of writing, the state of the art is probably the [GigaGAN](https://mingukkang.github.io/GigaGAN/) combining convolutional and self-attention layers in both the generator and the discriminator to ensure better \"flowing\" of the gradients while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a249ca05-46a0-412b-ad75-8319eac0bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "## We are using now two different optimizers the generator and the discriminator\n",
    "## We favour RMSprop over Adam because it follows smoother paths than Adam, \n",
    "## which may break the equilibrium between the two players.\n",
    "g_optimizer = RMSprop(1e-4)\n",
    "d_optimizer = RMSprop(5e-4)\n",
    "\n",
    "def train_step (data):\n",
    "    g_vars = generator.trainable_weights\n",
    "    d_vars = discriminator.trainable_weights\n",
    "    \n",
    "    ## Two gradient tapes are defined for the two networks\n",
    "    with tf.GradientTape() as g_tp, tf.GradientTape() as d_tp:\n",
    "        \n",
    "        ## Forward pass:\n",
    "        ## 1. generate the images \n",
    "        generated = generator(tf.random.normal(data.shape))\n",
    "        ## 2. apply the discriminator to the generated figures\n",
    "        d_gen = discriminator(generated)\n",
    "        ## 3. apply the discriminator to the real data\n",
    "        d_ref = discriminator(data)\n",
    "        \n",
    "        ## Compute the loss of the discriminator as a simple cross-entropy\n",
    "        n = tf.shape(d_gen)[0]\n",
    "        d_loss = (\n",
    "            BinaryCrossentropy()(tf.fill(n, 0.9), d_gen) + \n",
    "            BinaryCrossentropy()(tf.fill(n, 0.1), d_ref)\n",
    "        )\n",
    "        \n",
    "        ## Define the loss function of the generator\n",
    "        g_loss = -d_loss\n",
    "        \n",
    "    ## Then apply the usual scheme to compute and apply gradients\n",
    "    g_grads = g_tp.gradient(g_loss, g_vars)\n",
    "    d_grads = d_tp.gradient(d_loss, d_vars)\n",
    "    \n",
    "    g_optimizer.apply_gradients(zip(g_grads, g_vars))\n",
    "    d_optimizer.apply_gradients(zip(d_grads, d_vars))\n",
    "\n",
    "    return d_loss\n",
    "    \n",
    "def test_step (data):\n",
    "    generated = generator(tf.random.normal(data.shape))\n",
    "    d_gen = discriminator(generated)\n",
    "    d_ref = discriminator(data)\n",
    "    \n",
    "    n = tf.shape(data)[0]\n",
    "        \n",
    "    loss = (\n",
    "        BinaryCrossentropy()(tf.fill(n, 0.9), d_gen) + \n",
    "        BinaryCrossentropy()(tf.fill(n, 0.1), d_ref)\n",
    "    )\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "chunks = [tf.constant(c) for c in np.split(px_train, 100)[:-1]]\n",
    "label_chunks = [tf.constant(c, dtype=tf.float32) for c in np.split(y_train, 100)[:-1]]\n",
    "\n",
    "val_chunk = tf.constant(px_test[:1000])\n",
    "val_label = tf.constant(y_test[:1000], dtype=tf.float32)\n",
    "\n",
    "\n",
    "## Reset the weights\n",
    "from tensorflow.keras.models import clone_model\n",
    "generator = clone_model(generator)\n",
    "discriminator = clone_model(discriminator)\n",
    "\n",
    "from tqdm import trange\n",
    "for epoch in trange(100):\n",
    "    for chunk in chunks:\n",
    "        losses.append(train_step(chunk))\n",
    "        val_losses.append(test_step(val_chunk))\n",
    "\n",
    "plt.plot(losses, label=\"Training\")\n",
    "plt.plot(val_losses, label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652d435-fd87-4bbf-8ad8-2528b7fe0a2d",
   "metadata": {},
   "source": [
    "### Comments on the loss evolution\n",
    "Reading the loss of an Adversarial network is difficult. A high value of the loss may indicate both that the generator is excellent reproducing the original dataset or that the discriminator is extremely bad at classifying entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc50da2-7cfd-452b-a739-b4de9e5859db",
   "metadata": {},
   "source": [
    "### Let's visualize the generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2eb67e-ddb9-42c3-9d17-9aece51fedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = generator.predict(np.random.normal(0, 1, (64, 28, 28)))\n",
    "rough_inspection(generated)\n",
    "rough_inspection(val_chunk.numpy()[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c46d01-66c3-40c4-baa8-95eab444822d",
   "metadata": {},
   "source": [
    "We observe they are somewhat similar to digits, or letters, but they do not really make sense.\n",
    "The generator has no notion of what a digit is and digit a rather different from each other that it is \"inventing\" new digits. \n",
    "This is the extreme opposite of the behaviour we discussed above for autoencoders.\n",
    "\n",
    "Both effects can be mitigated by using more complex neural networks, better loss functions and longer trainings, but the conceptual difference between the solution of an autoencoder and that of a GAN remains. **GANs** are generally more \"creative\" than the autoencoders used as generators, but Autoencoders are so much easier to train, that sometimes they are still preferred over GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e97dd7f-6427-4325-ad96-4b8a4c783937",
   "metadata": {},
   "source": [
    "# Conditioning a GAN\n",
    "\n",
    "As we have conditioned the generation of digits from the decoder, defining a properly shaped noise function, here we try to modify the behaviour of the generator using a condition (once again, the label of the digit).\n",
    "\n",
    "In general, a conditional GAN (cGAN) is a type of GAN that can generate images conditioned on some additional information, such as class labels, text descriptions, or other modalities. A cGAN still consists of two neural networks: a generator that produces synthetic images from a random input and a conditional input, and a discriminator that tries to distinguish between real and fake images given the same conditional input. The conditional input can be concatenated with the random input for the generator, and with the image input for the discriminator. The goal of the cGAN is to find a Nash equilibrium where the generator produces realistic data that match the conditional input, and the discriminator cannot tell them apart from the real dataset.\n",
    "\n",
    "A cGAN can have various applications, such as image-to-image translation, image inpainting, text-to-image synthesis, and style transfer. A cGAN can also improve the quality and diversity of the generated images compared to an unconditional GAN, since it can leverage the additional information to guide the generation process.\n",
    "\n",
    "To condition the GAN we will need to rewrite a bit of out computation graph. We will still have at the core of the algorithm two CNNs, but now the input of the generator has to be the label and the discriminator must take a concatenation of the generated image and some representation of the label.\n",
    "\n",
    "> **Hint.** We are using a LeakyReLU loss function which reduces problems connected to gradient vanishing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb59ddd-642e-448d-8b46-426ea427ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as K\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "## This represents the generator inputs: the label and \n",
    "label = K.Input(10, dtype=tf.float32, name=\"label\")/10 - 0.5\n",
    "noise = tf.random.normal((tf.shape(label)[0], 64), 0., 1., name=\"noise\")\n",
    "\n",
    "## Then we concatenate the noise and the one-hot encoded label\n",
    "labeled_noise = K.layers.Concatenate(axis=1)((label, noise))\n",
    "\n",
    "## We define our generator architecture as a CNN similar to our former decoder\n",
    "generator_dnn = Sequential([\n",
    "    Dense(7*7*6, activation='linear', kernel_initializer='he_normal'),\n",
    "    LeakyReLU(),\n",
    "    Reshape((7, 7, 6)),\n",
    "    Conv2DTranspose(32, kernel_size=(3,3), activation='linear', padding='same'),\n",
    "    LeakyReLU(),\n",
    "    UpSampling2D(size=(2,2)),\n",
    "    Conv2DTranspose(16, kernel_size=(3,3), activation='linear', padding='same'),\n",
    "    LeakyReLU(),\n",
    "    UpSampling2D(size=(2,2)),\n",
    "    K.layers.Rescaling(10., offset=-5),\n",
    "    Conv2DTranspose(1, kernel_size=(3,3), activation='sigmoid', padding='same'),\n",
    "    Reshape((28, 28))\n",
    "], name=\"generator_cnn\")\n",
    "\n",
    "## We apply the generator to our preprocessed, concatenated input\n",
    "generated = generator_dnn(labeled_noise)\n",
    "\n",
    "## We define the generator model identifying its inputs and outputs\n",
    "generator = K.models.Model(inputs=label, outputs=generated, name=\"generator\")\n",
    "\n",
    "display(generator.summary())\n",
    "\n",
    "#######\n",
    "## Let's start with the discriminator, now\n",
    "\n",
    "## The discriminator's input is a 28x28 image, either generated or picked from \n",
    "## the reference sample.\n",
    "generated_or_reference = K.Input((28, 28), dtype=tf.float32, name=\"gen_or_ref\")\n",
    "\n",
    "## To be able to concatenate the labels to the images, we need to reshape the \n",
    "## labels to match a 28x28 grayscale image, let's do it with a shallow network\n",
    "label_mapper = Sequential([\n",
    "    Dense(28*28, activation='sigmoid'),\n",
    "    Reshape((28, 28, 1))\n",
    "], name=\"label_mapper\")\n",
    "\n",
    "## Then we concatenate the mapped lables with the 28x28 images\n",
    "labeled_generated = K.layers.Concatenate(axis=-1)((label_mapper(label), generated_or_reference[..., None]))\n",
    "\n",
    "## Let's define the discriminator, with an architecture similar to that of our encoder\n",
    "## it should read an image and output a classifier: 1 if the image is generated, or 0 if it is obtained from a reference sample\n",
    "discriminator_dnn = Sequential([\n",
    "    Conv2D(16, kernel_size=(5,5), activation='linear', padding='same', kernel_regularizer=L2(1e-3)),\n",
    "    LeakyReLU(),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(8, kernel_size=(5,5), activation='linear', padding='same', kernel_regularizer=L2(1e-3)),\n",
    "    LeakyReLU(),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(4, kernel_size=(5,5), activation='linear', padding='same', kernel_regularizer=L2(1e-3)),\n",
    "    LeakyReLU(),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='linear', kernel_initializer='he_normal'),\n",
    "    LeakyReLU(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name=\"discriminator_cnn\")\n",
    "\n",
    "## We describe the forward pass \n",
    "classifier = discriminator_dnn(labeled_generated)\n",
    "\n",
    "## And then we define the model identifying who is the input and who is the output\n",
    "discriminator = K.models.Model(inputs=(label, generated_or_reference), outputs=classifier, name=\"discriminator\")\n",
    "\n",
    "display(discriminator.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b13b5-0724-4ebc-830c-3ec5e0e57a8d",
   "metadata": {},
   "source": [
    "The forward pass is rather similar the one we have discussed above and in previous lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac6b9a-1815-423c-8b10-f84b52421427",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optimizer = Adam(1e-4)\n",
    "d_optimizer = Adam(5e-4)\n",
    "\n",
    "def train_step (data, label):\n",
    "    g_vars = generator.trainable_weights\n",
    "    d_vars = discriminator.trainable_weights\n",
    "    \n",
    "    with tf.GradientTape() as g_tp, tf.GradientTape() as d_tp:\n",
    "        generated = generator(label)\n",
    "        d_gen = discriminator((label, generated))\n",
    "        d_ref = discriminator((label, data))\n",
    "        n = tf.shape(d_gen)[0]\n",
    "        d_loss = (\n",
    "            BinaryCrossentropy()(tf.fill(n, 0.99), d_gen) + \n",
    "            BinaryCrossentropy()(tf.fill(n, 0.01), d_ref)\n",
    "        )\n",
    "        g_loss = -d_loss\n",
    "        \n",
    "    g_grads = g_tp.gradient(g_loss, g_vars)\n",
    "    d_grads = d_tp.gradient(d_loss, d_vars)\n",
    "\n",
    "    g_optimizer.apply_gradients(zip(g_grads, g_vars))\n",
    "    d_optimizer.apply_gradients(zip(d_grads, d_vars))\n",
    "\n",
    "    return d_loss\n",
    "    \n",
    "def test_step (data, label):\n",
    "    generated = generator(label)\n",
    "    d_gen = discriminator((label, generated))\n",
    "    d_ref = discriminator((label, data))\n",
    "    \n",
    "    n = tf.shape(data)[0]\n",
    "        \n",
    "    loss = (\n",
    "        BinaryCrossentropy()(tf.fill(n, 0.99), d_gen) + \n",
    "        BinaryCrossentropy()(tf.fill(n, 0.01), d_ref)\n",
    "    )\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "chunks = [tf.constant(c) for c in np.split(px_train, 100)[:-1]]\n",
    "label_chunks = [tf.constant(c, dtype=tf.float32) for c in np.split(py_train, 100)[:-1]]\n",
    "\n",
    "val_chunk = tf.constant(px_test[:1000])\n",
    "val_label = tf.constant(py_test[:1000], dtype=tf.float32)\n",
    "\n",
    "\n",
    "## Reset the weights\n",
    "from tensorflow.keras.models import clone_model\n",
    "generator = clone_model(generator)\n",
    "discriminator = clone_model(discriminator)\n",
    "\n",
    "from tqdm import trange\n",
    "for epoch in trange(100):\n",
    "    for chunk, labels in zip(chunks, label_chunks):\n",
    "        losses.append(train_step(chunk, labels))\n",
    "        val_losses.append(test_step(val_chunk, val_label))\n",
    "        \n",
    "plt.plot(losses, label=\"Training\")\n",
    "plt.plot(val_losses, label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed1bafc-0603-46e2-8641-4db0fa7ef3e7",
   "metadata": {},
   "source": [
    "But now we are able to request generated digits from a given family and obtain a sample of 1, 2, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fbe96-4143-4002-a22d-d953b025ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rough_inspection(val_chunk.numpy()[:64], n_fig=8)\n",
    "\n",
    "for example_digit in 1, 2, 5:\n",
    "    generated = generator.predict([[i==example_digit for i in range(10)] for _ in range(64)])\n",
    "    rough_inspection(generated, n_fig=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e4afa-7690-4f3f-8d49-46a345ba6996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d19b2-5a12-4b6b-a2c0-bb2378b53d36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HEP",
   "language": "python",
   "name": "hep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
